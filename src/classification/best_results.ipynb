{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880590</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>0.922089</td>\n",
       "      <td>252230.000000</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744658</td>\n",
       "      <td>0.417934</td>\n",
       "      <td>0.535386</td>\n",
       "      <td>56863.000000</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.812624</td>\n",
       "      <td>0.692813</td>\n",
       "      <td>0.728738</td>\n",
       "      <td>309093.000000</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.855583</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.850948</td>\n",
       "      <td>309093.000000</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score        support  \\\n",
       "0              0.880590  0.967692  0.922089  252230.000000   \n",
       "1              0.744658  0.417934  0.535386   56863.000000   \n",
       "accuracy       0.866555  0.866555  0.866555       0.866555   \n",
       "macro avg      0.812624  0.692813  0.728738  309093.000000   \n",
       "weighted avg   0.855583  0.866555  0.850948  309093.000000   \n",
       "\n",
       "                                                       model  \n",
       "0             mlp-micro-2-avg_agression_per_topic-0.01-32-64  \n",
       "1             mlp-micro-2-avg_agression_per_topic-0.01-32-64  \n",
       "accuracy      mlp-micro-2-avg_agression_per_topic-0.01-32-64  \n",
       "macro avg     mlp-micro-2-avg_agression_per_topic-0.01-32-64  \n",
       "weighted avg  mlp-micro-2-avg_agression_per_topic-0.01-32-64  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from consts import HOME_PATH\n",
    "\n",
    "report_all = pd.read_pickle(f\"{HOME_PATH}mlp/results_df.pkl\")\n",
    "report_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>model</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.880590</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>0.922089</td>\n",
       "      <td>252230.000000</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.744658</td>\n",
       "      <td>0.417934</td>\n",
       "      <td>0.535386</td>\n",
       "      <td>56863.000000</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.812624</td>\n",
       "      <td>0.692813</td>\n",
       "      <td>0.728738</td>\n",
       "      <td>309093.000000</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.855583</td>\n",
       "      <td>0.866555</td>\n",
       "      <td>0.850948</td>\n",
       "      <td>309093.000000</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.01-32-64</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>0</td>\n",
       "      <td>0.894411</td>\n",
       "      <td>0.948016</td>\n",
       "      <td>0.920433</td>\n",
       "      <td>252230.000000</td>\n",
       "      <td>mlp-class-0.001-100-128</td>\n",
       "      <td>mlp-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>1</td>\n",
       "      <td>0.685910</td>\n",
       "      <td>0.503561</td>\n",
       "      <td>0.580758</td>\n",
       "      <td>56863.000000</td>\n",
       "      <td>mlp-class-0.001-100-128</td>\n",
       "      <td>mlp-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>mlp-class-0.001-100-128</td>\n",
       "      <td>mlp-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.790160</td>\n",
       "      <td>0.725788</td>\n",
       "      <td>0.750596</td>\n",
       "      <td>309093.000000</td>\n",
       "      <td>mlp-class-0.001-100-128</td>\n",
       "      <td>mlp-class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.856053</td>\n",
       "      <td>0.866251</td>\n",
       "      <td>0.857944</td>\n",
       "      <td>309093.000000</td>\n",
       "      <td>mlp-class-0.001-100-128</td>\n",
       "      <td>mlp-class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1620 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric  precision    recall  f1-score        support  \\\n",
       "0                0   0.880590  0.967692  0.922089  252230.000000   \n",
       "1                1   0.744658  0.417934  0.535386   56863.000000   \n",
       "2         accuracy   0.866555  0.866555  0.866555       0.866555   \n",
       "3        macro avg   0.812624  0.692813  0.728738  309093.000000   \n",
       "4     weighted avg   0.855583  0.866555  0.850948  309093.000000   \n",
       "...            ...        ...       ...       ...            ...   \n",
       "1615             0   0.894411  0.948016  0.920433  252230.000000   \n",
       "1616             1   0.685910  0.503561  0.580758   56863.000000   \n",
       "1617      accuracy   0.866251  0.866251  0.866251       0.866251   \n",
       "1618     macro avg   0.790160  0.725788  0.750596  309093.000000   \n",
       "1619  weighted avg   0.856053  0.866251  0.857944  309093.000000   \n",
       "\n",
       "                                               model  \\\n",
       "0     mlp-micro-2-avg_agression_per_topic-0.01-32-64   \n",
       "1     mlp-micro-2-avg_agression_per_topic-0.01-32-64   \n",
       "2     mlp-micro-2-avg_agression_per_topic-0.01-32-64   \n",
       "3     mlp-micro-2-avg_agression_per_topic-0.01-32-64   \n",
       "4     mlp-micro-2-avg_agression_per_topic-0.01-32-64   \n",
       "...                                              ...   \n",
       "1615                         mlp-class-0.001-100-128   \n",
       "1616                         mlp-class-0.001-100-128   \n",
       "1617                         mlp-class-0.001-100-128   \n",
       "1618                         mlp-class-0.001-100-128   \n",
       "1619                         mlp-class-0.001-100-128   \n",
       "\n",
       "                               model_type  \n",
       "0     mlp-micro-2-avg_agression_per_topic  \n",
       "1     mlp-micro-2-avg_agression_per_topic  \n",
       "2     mlp-micro-2-avg_agression_per_topic  \n",
       "3     mlp-micro-2-avg_agression_per_topic  \n",
       "4     mlp-micro-2-avg_agression_per_topic  \n",
       "...                                   ...  \n",
       "1615                            mlp-class  \n",
       "1616                            mlp-class  \n",
       "1617                            mlp-class  \n",
       "1618                            mlp-class  \n",
       "1619                            mlp-class  \n",
       "\n",
       "[1620 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_all = report_all.reset_index()\n",
    "report_all= report_all.rename(columns={\"index\": \"metric\"})\n",
    "report_all['model_type'] = report_all['model'].str.split('-0', 1).str[0]\n",
    "report_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309093, 106)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 106)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from load_data import reduce_set, load_data_conformity_based\n",
    "from grid_search import prepare_data_topic_based\n",
    "\n",
    "X_test, y_test = load_data_conformity_based(\"test\")\n",
    "print(X_test.shape)\n",
    "X_test_reduced, y_test_reduced = reduce_set(X_test, y_test)\n",
    "X_test_reduced.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.411633391891762%\n"
     ]
    }
   ],
   "source": [
    "print(f'{(X_test_reduced.shape[0] / X_test.shape[0]) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mlp-micro-2-avg_agression_per_topic',\n",
       "       'mlp-micro-2-avg_agression_score_per_topic',\n",
       "       'mlp-micro-2-avg_agression_score_per_topic_normalized',\n",
       "       'mlp-micro-2-mean_std_agression_score_per_topic', 'mlp-baseline',\n",
       "       'mlp-conformity', 'mlp-micro-5-mean_std_agression_score_per_topic',\n",
       "       'mlp-micro-5-avg_agression_per_topic',\n",
       "       'mlp-micro-5-avg_agression_score_per_topic',\n",
       "       'mlp-micro-5-avg_agression_score_per_topic_normalized',\n",
       "       'mlp-micro-13-mean_std_agression_score_per_topic',\n",
       "       'mlp-micro-13-avg_agression_per_topic',\n",
       "       'mlp-micro-13-avg_agression_score_per_topic',\n",
       "       'mlp-micro-13-avg_agression_score_per_topic_normalized',\n",
       "       'mlp-macro-2-mean_std_agression_score_per_topic',\n",
       "       'mlp-macro-2-avg_agression_per_topic',\n",
       "       'mlp-macro-2-avg_agression_score_per_topic',\n",
       "       'mlp-macro-2-avg_agression_score_per_topic_normalized',\n",
       "       'mlp-macro-4-mean_std_agression_score_per_topic',\n",
       "       'mlp-macro-4-avg_agression_per_topic',\n",
       "       'mlp-macro-4-avg_agression_score_per_topic',\n",
       "       'mlp-macro-4-avg_agression_score_per_topic_normalized',\n",
       "       'mlp-macro-6-mean_std_agression_score_per_topic',\n",
       "       'mlp-macro-6-avg_agression_per_topic',\n",
       "       'mlp-macro-6-avg_agression_score_per_topic',\n",
       "       'mlp-macro-6-avg_agression_score_per_topic_normalized',\n",
       "       'mlp-class'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_all[\"model_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>model</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.870136</td>\n",
       "      <td>0.870136</td>\n",
       "      <td>0.870136</td>\n",
       "      <td>0.870136</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic-0.001-32-128</td>\n",
       "      <td>mlp-micro-2-avg_agression_per_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.865280</td>\n",
       "      <td>0.865280</td>\n",
       "      <td>0.865280</td>\n",
       "      <td>0.865280</td>\n",
       "      <td>mlp-micro-2-avg_agression_score_per_topic-0.00...</td>\n",
       "      <td>mlp-micro-2-avg_agression_score_per_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.864733</td>\n",
       "      <td>0.864733</td>\n",
       "      <td>0.864733</td>\n",
       "      <td>0.864733</td>\n",
       "      <td>mlp-micro-2-avg_agression_score_per_topic_norm...</td>\n",
       "      <td>mlp-micro-2-avg_agression_score_per_topic_norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.865193</td>\n",
       "      <td>0.865193</td>\n",
       "      <td>0.865193</td>\n",
       "      <td>0.865193</td>\n",
       "      <td>mlp-micro-2-mean_std_agression_score_per_topic...</td>\n",
       "      <td>mlp-micro-2-mean_std_agression_score_per_topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric  precision    recall  f1-score   support  \\\n",
       "37   accuracy   0.870136  0.870136  0.870136  0.870136   \n",
       "102  accuracy   0.865280  0.865280  0.865280  0.865280   \n",
       "162  accuracy   0.864733  0.864733  0.864733  0.864733   \n",
       "187  accuracy   0.865193  0.865193  0.865193  0.865193   \n",
       "\n",
       "                                                 model  \\\n",
       "37    mlp-micro-2-avg_agression_per_topic-0.001-32-128   \n",
       "102  mlp-micro-2-avg_agression_score_per_topic-0.00...   \n",
       "162  mlp-micro-2-avg_agression_score_per_topic_norm...   \n",
       "187  mlp-micro-2-mean_std_agression_score_per_topic...   \n",
       "\n",
       "                                            model_type  \n",
       "37                 mlp-micro-2-avg_agression_per_topic  \n",
       "102          mlp-micro-2-avg_agression_score_per_topic  \n",
       "162  mlp-micro-2-avg_agression_score_per_topic_norm...  \n",
       "187     mlp-micro-2-mean_std_agression_score_per_topic  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_models():\n",
    "    # report_ones = report_all.loc[report_all['metric'] == '1', :]\n",
    "    # report_ones.loc[report_ones.groupby(['model_type'])['recall'].idxmax()]\n",
    "\n",
    "\n",
    "    report_accuracy = report_all.loc[report_all['metric'] == 'accuracy', :]\n",
    "    report_accuracy = report_accuracy.loc[report_accuracy.groupby(['model_type'])['precision'].idxmax()]\n",
    "    return report_accuracy\n",
    "\n",
    "get_best_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION macro\n",
      "\t0.817\t0.816\t0.806\t0.809\n",
      "PRECISION class-1\n",
      "\t0.750\t0.754\t0.730\t0.738\n",
      "RECALL macro\n",
      "\t0.704\t0.684\t0.695\t0.689\n",
      "RECALL class-1\n",
      "\t0.441\t0.397\t0.425\t0.410\n",
      "F1-SCORE micro\n",
      "\t0.870\t0.865\t0.865\t0.865\n",
      "F1-SCORE class-1\n",
      "\t0.555\t0.520\t0.537\t0.527\n"
     ]
    }
   ],
   "source": [
    "# # print latex-format\n",
    "from user_metrics import (\n",
    "    avg_agression_per_topic,\n",
    "    avg_agression_score_per_topic,\n",
    "    avg_agression_score_per_topic_normalized,\n",
    "    mean_std_agression_score_per_topic,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def results_for_latex_table(metric, index_n):\n",
    "    for variant in [\"micro-2\"]: #[\"micro-2\", \"macro-4\", \"macro-6\", \"micro-2\", \"micro-5\", \"micro-13\"]:\n",
    "        res = ''\n",
    "        for func in [avg_agression_per_topic, avg_agression_score_per_topic, mean_std_agression_score_per_topic, avg_agression_score_per_topic_normalized]:\n",
    "            res += f'\\t{bests_f1.loc[bests_f1[\"model_type\"] == f\"mlp-{variant}-{func.__name__}\", [metric]].iloc[index_n, 0]:.3f}'\n",
    "        print(res)\n",
    "\n",
    "metrics = [\"precision\" for i in range(2)] + [\"recall\" for i in range(2)] + [\"f1-score\" for i in range(2)]\n",
    "index_n = [3, 1, 3, 1, 2, 1]\n",
    "names_sufix = [\"macro\", \"class-1\", \"macro\", \"class-1\", \"micro\", \"class-1\"]\n",
    "\n",
    "for metric, index, suffix in zip(metrics, index_n, names_sufix):\n",
    "    print(f\"{metric.upper()} {suffix}\")\n",
    "    results_for_latex_table(metric, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION macro\n",
      "PRECISION class-1\n",
      "RECALL macro\n",
      "RECALL class-1\n",
      "F1-SCORE micro\n",
      "F1-SCORE class-1\n",
      "mlp-baseline-0.001-32-128\n",
      "\t0.794\t0.711\t0.681\t0.399\t0.860\t0.511\n",
      "mlp-conformity-0.001-32-128\n",
      "\t0.803\t0.708\t0.738\t0.524\t0.873\t0.602\n",
      "mlp-micro-2-avg_agression_per_topic-0.001-32-128\n",
      "\t0.817\t0.750\t0.704\t0.441\t0.870\t0.555\n"
     ]
    }
   ],
   "source": [
    "from results import get_best_results, add_column_model_type,get_best_models_names\n",
    "\n",
    "\n",
    "def get_best_models_names_by_method_type(results_all):\n",
    "    results_all = add_column_model_type(results_all)\n",
    "\n",
    "    results_all[\"method_type\"] = results_all[\"model\"].str.split(\"-\",3).str[1]\n",
    "    results_all.loc[results_all[\"method_type\"].isin([\"micro\", \"macro\"]), \"method_type\"] = \"topic-based\"\n",
    "\n",
    "    results_accuracy = results_all.loc[results_all[\"metric\"] == \"accuracy\", :]\n",
    "    results_bests = results_accuracy.loc[results_accuracy.groupby([\"method_type\"])[\"precision\"].idxmax()]\n",
    "    best_models_names = results_bests[\"model\"].tolist()  \n",
    "    return best_models_names\n",
    "\n",
    "# in latex-format\n",
    "def print_bests_results():\n",
    "    results_all = pd.read_pickle(f\"{HOME_PATH}mlp/results_df.pkl\")\n",
    "    bests_models_names = get_best_models_names_by_method_type(results_all)\n",
    "    \n",
    "    metrics = (\n",
    "        [\"precision\" for _ in range(2)]\n",
    "        + [\"recall\" for _ in range(2)]\n",
    "        + [\"f1-score\" for _ in range(2)]\n",
    "    )\n",
    "    index_n = [3, 1, 3, 1, 2, 1]\n",
    "    names_sufix = [\"macro\", \"class-1\", \"macro\", \"class-1\", \"micro\", \"class-1\"]\n",
    "    \n",
    "    [print(f'{metric.upper()} {suffix}') for metric, suffix in zip(metrics, names_sufix)]\n",
    "\n",
    "    for model_name in bests_models_names:\n",
    "        result = ''\n",
    "        print(model_name)\n",
    "        for metric, index in zip(metrics, index_n):\n",
    "            result += f'\\t{results_all.loc[results_all[\"model\"] == model_name, [metric]].iloc[index, 0]:.3f}'\n",
    "\n",
    "        print(result)\n",
    "\n",
    "print_bests_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba użytkowników, którze nie mieli żadnej poztywnej (agresywnej) anotacji 75\n"
     ]
    }
   ],
   "source": [
    "from load_data import join_embedding\n",
    "from consts import HOME_PATH\n",
    "import pandas as pd\n",
    "\n",
    "df_annotations = pd.read_pickle(f\"{HOME_PATH}df_anno_dev.pkl\")\n",
    "df_annotations = join_embedding(df_annotations)\n",
    "\n",
    "# class-based -> ilu uzytkownikow dostalo same zera, bo nie dalo sie policzyc metryki\n",
    "print(f'Liczba użytkowników, którze nie mieli żadnej poztywnej (agresywnej) anotacji {(df_annotations[\"worker_id\"].nunique() * 2) - df_annotations.groupby(by=[\"worker_id\", \"aggression\"]).count().shape[0]}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d41587b1448a779064ac33a32e943fc6647f5c1e0872f91ac9888f04b933bee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
